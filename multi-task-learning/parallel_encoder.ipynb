{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33a039fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2efce1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_pairs(root_dir):\n",
    "    \"\"\"Tìm cặp file rung động và tốc độ, gán nhãn dựa trên tên.\"\"\"\n",
    "    pairs = []\n",
    "    label_map = {'normal': 0, 'inner': 1, 'outer': 2, 'ball': 3}\n",
    "    \n",
    "    # Lấy danh sách tất cả file csv\n",
    "    all_files = [f for f in os.listdir(root_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # Tìm các file rung động (vibration)\n",
    "    vib_files = [f for f in all_files if 'vibration' in f.lower()]\n",
    "    \n",
    "    for v_file in vib_files:\n",
    "        # Xác định nhãn sức khỏe\n",
    "        assigned_label = None\n",
    "        for key, val in label_map.items():\n",
    "            if key in v_file.lower():\n",
    "                assigned_label = val\n",
    "                break\n",
    "        \n",
    "        if assigned_label is None: continue\n",
    "\n",
    "        # Tìm file tốc độ tương ứng\n",
    "        s_file = v_file.lower().replace('vibration', 'rpm')\n",
    "        \n",
    "        if s_file in [f.lower() for f in all_files]:\n",
    "            v_path = os.path.join(root_dir, v_file)\n",
    "            # Lấy tên file speed thực tế (giữ nguyên hoa thường)\n",
    "            actual_s_file = [f for f in all_files if f.lower() == s_file][0]\n",
    "            s_path = os.path.join(root_dir, actual_s_file)\n",
    "            pairs.append((v_path, s_path, assigned_label))\n",
    "            \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def process_data_to_tensors(file_pairs, segment_length=2048):\n",
    "    all_vib, all_speed, all_fault = [], [], []\n",
    "    step = segment_length // 2 # Overlap 50%\n",
    "    \n",
    "    for v_path, s_path, label in file_pairs:\n",
    "        print(f\"Đang xử lý: {os.path.basename(v_path)} & {os.path.basename(s_path)}\")\n",
    "        \n",
    "        # Đọc dữ liệu (7,680,000 mẫu)\n",
    "        v_data = pd.read_csv(v_path).iloc[:, 0].values.astype(np.float32)\n",
    "        s_data = pd.read_csv(s_path).iloc[:, 0].values.astype(np.float32)\n",
    "        \n",
    "        # Xác định độ dài tối thiểu của cả 2 file để tránh lệch index\n",
    "        min_len = min(len(v_data), len(s_data))\n",
    "        \n",
    "        # Phân đoạn với Overlap 50%\n",
    "        for start in range(0, min_len - segment_length + 1, step):\n",
    "            end = start + segment_length\n",
    "            \n",
    "            # Trích xuất đoạn thô\n",
    "            v_seg_raw = v_data[start:end]\n",
    "            s_seg_raw = s_data[start:end] # Tốc độ giữ nguyên không chuẩn hóa\n",
    "            \n",
    "            # Kiểm tra độ dài chặt chẽ để tránh lỗi ValueError khi vstack\n",
    "            if len(v_seg_raw) == segment_length and len(s_seg_raw) == segment_length:\n",
    "                # 1. Chuẩn hóa Rung động theo từng mẫu [-1, 1] như bạn muốn\n",
    "                v_min, v_max = np.min(v_seg_raw), np.max(v_seg_raw)\n",
    "                v_seg_norm = 2 * (v_seg_raw - v_min) / (v_max - v_min + 1e-6) - 1\n",
    "                \n",
    "                # 2. Lưu dữ liệu (Tốc độ s_seg_raw được giữ nguyên giá trị RPM thực)\n",
    "                all_vib.append(v_seg_norm.reshape(1, -1))\n",
    "                all_speed.append(s_seg_raw.reshape(1, -1))\n",
    "                all_fault.append(label)\n",
    "            \n",
    "    # Xếp chồng các mảng (Kích thước đồng nhất nên vstack sẽ không lỗi)\n",
    "    vib_array = np.vstack(all_vib)\n",
    "    speed_array = np.vstack(all_speed)\n",
    "    \n",
    "    # Chuyển đổi sang Tensor và thêm chiều channel (1) cho CNN 1D [cite: 319-322]\n",
    "    return (torch.FloatTensor(vib_array).unsqueeze(1), \n",
    "            torch.FloatTensor(speed_array).unsqueeze(1), \n",
    "            torch.LongTensor(np.array(all_fault)))\n",
    "\n",
    "class MDAMDataset(Dataset):\n",
    "    def __init__(self, vib, speed, fault):\n",
    "        self.vib, self.speed, self.fault = vib, speed, fault\n",
    "    def __len__(self): return len(self.vib)\n",
    "    def __getitem__(self, idx): return self.vib[idx], self.speed[idx], self.fault[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74f65d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.attention_path = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 2, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2, 1, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(1, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = self.attention_path(x)\n",
    "        return x * mask + x\n",
    "\n",
    "class EncoderBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderBranch, self).__init__()\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv1d(1, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv1d(128, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv1d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 4\n",
    "            nn.Conv1d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Block 5\n",
    "            nn.Conv1d(8, 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.attention = AttentionModule(4)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4 * 64, 100),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class MultiHeadEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadEncoder, self).__init__()\n",
    "        self.speed_encoder = EncoderBranch()\n",
    "        self.fault_encoder = EncoderBranch()\n",
    "\n",
    "    def forward(self, x):\n",
    "        speed_features = self.speed_encoder(x)\n",
    "        fault_features = self.fault_encoder(x)\n",
    "        return speed_features, fault_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c30c3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim=100, num_classes=3):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "    \n",
    "\n",
    "class SpeedDecoder(nn.Module):\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(SpeedDecoder, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(feature_dim, 256), nn.ELU())\n",
    "        self.prepare = nn.Linear(256, 4 * 64) \n",
    "        \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose1d(4, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose1d(4, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, r_speed):\n",
    "        x = self.fc(r_speed)\n",
    "        x = self.prepare(x).view(-1, 4, 64)\n",
    "        return self.deconv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da91971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Module Decoder để tái tạo tín hiệu từ đặc trưng tốc độ và lỗi.\"\"\"\n",
    "    def __init__(self, feature_dim=100):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_init = nn.Sequential(\n",
    "            nn.Linear(feature_dim * 2, 256),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        self.prepare_conv = nn.Linear(256, 4 * 64)\n",
    "        \n",
    "        self.deconv_blocks = nn.Sequential(\n",
    "            nn.ConvTranspose1d(4, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.ConvTranspose1d(128, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.ConvTranspose1d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ELU(),\n",
    "            \n",
    "            nn.ConvTranspose1d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, speed_features, fault_features):\n",
    "        combined = torch.cat((speed_features, fault_features), dim=1)\n",
    "        \n",
    "        x = self.fc_init(combined)\n",
    "        \n",
    "        x = self.prepare_conv(x)\n",
    "        x = x.view(x.size(0), 4, 64) \n",
    "        \n",
    "        reconstructed_signal = self.deconv_blocks(x)\n",
    "        return reconstructed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a4393ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDAMModel(nn.Module):\n",
    "    def __init__(self, num_fault_classes=4):\n",
    "        super(MDAMModel, self).__init__()\n",
    "        \n",
    "        # 1. Multi-head Encoder [cite: 319, 311]\n",
    "        self.encoder = MultiHeadEncoder()\n",
    "        \n",
    "        # 2. Decoder cho Rung động (Vibration Reconstruction) [cite: 388]\n",
    "        self.decoder_vib = Decoder(feature_dim=100)\n",
    "        \n",
    "        # 3. Speed Decoder (Speed Reconstruction - Theo yêu cầu của bạn)\n",
    "        self.decoder_speed = SpeedDecoder(feature_dim=100)\n",
    "        \n",
    "        # 4. Fault Diagnosis Head (Phân loại 4 nhãn) [cite: 412]\n",
    "        self.fd_head = ClassificationHead(input_dim=100, num_classes=num_fault_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Trích xuất đặc trưng gỡ rối [cite: 115, 222]\n",
    "        r_speed, r_fault = self.encoder(x)\n",
    "        \n",
    "        # Tái tạo tín hiệu rung động (x_hat) [cite: 231]\n",
    "        vib_reconstructed = self.decoder_vib(r_speed, r_fault)\n",
    "        \n",
    "        # Tái tạo chuỗi tín hiệu tốc độ (z_hat)\n",
    "        speed_reconstructed = self.decoder_speed(r_speed)\n",
    "        \n",
    "        # Chẩn đoán lỗi (y_hat) [cite: 230]\n",
    "        fault_output = self.fd_head(r_fault)\n",
    "        \n",
    "        return vib_reconstructed, fault_output, speed_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e827d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý: vibration_ball_0.csv & rpm_ball_0.csv\n",
      "Đang xử lý: vibration_ball_1.csv & rpm_ball_1.csv\n",
      "Đang xử lý: vibration_inner_0.csv & rpm_inner_0.csv\n",
      "Đang xử lý: vibration_inner_1.csv & rpm_inner_1.csv\n",
      "Đang xử lý: vibration_normal_0.csv & rpm_normal_0.csv\n",
      "Đang xử lý: vibration_normal_1.csv & rpm_normal_1.csv\n",
      "Đang xử lý: vibration_outer_0.csv & rpm_outer_0.csv\n",
      "Đang xử lý: vibration_outer_1.csv & rpm_outer_1.csv\n",
      "Đang xử lý: vibration_ball_2.csv & rpm_ball_2.csv\n",
      "Đang xử lý: vibration_ball_3.csv & rpm_ball_3.csv\n",
      "Đang xử lý: vibration_ball_4.csv & rpm_ball_4.csv\n",
      "Đang xử lý: vibration_ball_5.csv & rpm_ball_5.csv\n",
      "Đang xử lý: vibration_ball_6.csv & rpm_ball_6.csv\n",
      "Đang xử lý: vibration_inner_2.csv & rpm_inner_2.csv\n",
      "Đang xử lý: vibration_inner_3.csv & rpm_inner_3.csv\n",
      "Đang xử lý: vibration_inner_4.csv & rpm_inner_4.csv\n",
      "Đang xử lý: vibration_inner_5.csv & rpm_inner_5.csv\n",
      "Đang xử lý: vibration_inner_6.csv & rpm_inner_6.csv\n",
      "Đang xử lý: vibration_normal_2.csv & rpm_normal_2.csv\n",
      "Đang xử lý: vibration_normal_3.csv & rpm_normal_3.csv\n",
      "Đang xử lý: vibration_normal_4.csv & rpm_normal_4.csv\n",
      "Đang xử lý: vibration_normal_5.csv & rpm_normal_5.csv\n",
      "Đang xử lý: vibration_normal_6.csv & rpm_normal_6.csv\n",
      "Đang xử lý: vibration_outer_2.csv & rpm_outer_2.csv\n",
      "Đang xử lý: vibration_outer_3.csv & rpm_outer_3.csv\n",
      "Đang xử lý: vibration_outer_4.csv & rpm_outer_4.csv\n",
      "Đang xử lý: vibration_outer_5.csv & rpm_outer_5.csv\n",
      "Đang xử lý: vibration_outer_6.csv & rpm_outer_6.csv\n"
     ]
    }
   ],
   "source": [
    "# Quy trình thực thi\n",
    "TRAIN_ROOT = r\"E:\\5m\\2nd\\training_set\"\n",
    "TEST_ROOT = r\"E:\\5m\\2nd\\test_set\"\n",
    "\n",
    "# 1. Xử lý tập Train & Validation\n",
    "train_pairs = get_matched_pairs(TRAIN_ROOT)\n",
    "v_train, s_train, f_train = process_data_to_tensors(train_pairs)\n",
    "full_ds = MDAMDataset(v_train, s_train, f_train)\n",
    "\n",
    "train_size = int(0.8 * len(full_ds))\n",
    "train_ds, val_ds = random_split(full_ds, [train_size, len(full_ds) - train_size])\n",
    "\n",
    "# 2. Xử lý tập Test\n",
    "test_pairs = get_matched_pairs(TEST_ROOT)\n",
    "v_test, s_test, f_test = process_data_to_tensors(test_pairs)\n",
    "test_ds = MDAMDataset(v_test, s_test, f_test)\n",
    "\n",
    "# 3. Tạo Loaders (Batch size 128 theo bài báo [cite: 305])\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c44bfd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KIỂM TRA THUỘC TÍNH DATASET ---\n",
      "1. Tổng số mẫu (Segments): 47987\n",
      "2. Shape của Rung động (Vibration): torch.Size([1, 2048])\n",
      "   Shape của Tốc độ (Speed): torch.Size([1, 2048])\n",
      "   Nhãn lỗi (Fault Label): 3\n",
      "3. Phạm vi giá trị Rung động: Min=-1.0000, Max=1.0000\n",
      "   Phạm vi giá trị Tốc độ: Min=2191.0000, Max=2216.0652\n",
      "4. Dtype: Vib=torch.float32, Speed=torch.float32, Fault=torch.int64\n"
     ]
    }
   ],
   "source": [
    "def check_dataset_properties(dataset):\n",
    "    print(\"--- KIỂM TRA THUỘC TÍNH DATASET ---\")\n",
    "    \n",
    "    # 1. Tổng số mẫu\n",
    "    total_samples = len(dataset)\n",
    "    print(f\"1. Tổng số mẫu (Segments): {total_samples}\")\n",
    "    \n",
    "    # Lấy mẫu\n",
    "    vib, speed, fault = dataset[0]\n",
    "    \n",
    "    # 2. Kiểm tra Shape\n",
    "    # Rung động \n",
    "    print(f\"2. Shape của Rung động (Vibration): {vib.shape}\")\n",
    "    # Tốc độ \n",
    "    print(f\"   Shape của Tốc độ (Speed): {speed.shape}\")\n",
    "    print(f\"   Nhãn lỗi (Fault Label): {fault.item()}\")\n",
    "    \n",
    "    # 3. Kiểm tra Value Ranges\n",
    "    print(f\"3. Phạm vi giá trị Rung động: Min={vib.min():.4f}, Max={vib.max():.4f}\")\n",
    "    print(f\"   Phạm vi giá trị Tốc độ: Min={speed.min():.4f}, Max={speed.max():.4f}\")\n",
    "    \n",
    "    # 4. Kiểm tra Kiểu dữ liệu (Dtype)\n",
    "    print(f\"4. Dtype: Vib={vib.dtype}, Speed={speed.dtype}, Fault={fault.dtype}\")\n",
    "    \n",
    "    # 5. Kiểm tra phân phối nhãn lỗi\n",
    "    if hasattr(dataset, 'fault'):\n",
    "        unique_labels, counts = torch.unique(dataset.fault, return_counts=True)\n",
    "        label_names = {0: 'Normal', 1: 'Inner', 2: 'Outer', 3: 'Ball'}\n",
    "        print(\"5. Phân phối nhãn lỗi:\")\n",
    "        for label, count in zip(unique_labels, counts):\n",
    "            name = label_names.get(label.item(), \"Unknown\")\n",
    "            print(f\"   - {name} ({label.item()}): {count.item()} mẫu\")\n",
    "\n",
    "# Sử dụng:\n",
    "check_dataset_properties(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d5d2511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đang sử dụng thiết bị: CUDA (NVIDIA GeForce GTX 1050 Ti) ---\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--- Đang sử dụng thiết bị: {device.type.upper()} \" + (f\"({torch.cuda.get_device_name(0)})\" if device.type == 'cuda' else \"\") + \" ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "933eccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu126\n",
      "True\n",
      "NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e1927f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Loss: 520140.6128 | Fault Acc: 61.08% | Val Acc: 61.34%\n",
      "Epoch [2/50] Loss: 70016.6394 | Fault Acc: 66.76% | Val Acc: 65.21%\n",
      "Epoch [3/50] Loss: 60659.3163 | Fault Acc: 68.99% | Val Acc: 67.40%\n",
      "Epoch [4/50] Loss: 52246.1559 | Fault Acc: 71.57% | Val Acc: 68.18%\n",
      "Epoch [5/50] Loss: 46656.4747 | Fault Acc: 73.68% | Val Acc: 70.09%\n",
      "Epoch [6/50] Loss: 39265.5676 | Fault Acc: 75.91% | Val Acc: 73.02%\n",
      "Epoch [7/50] Loss: 32906.0738 | Fault Acc: 77.94% | Val Acc: 75.76%\n",
      "Epoch [8/50] Loss: 30115.4244 | Fault Acc: 79.58% | Val Acc: 76.86%\n",
      "Epoch [9/50] Loss: 26609.6161 | Fault Acc: 81.22% | Val Acc: 73.12%\n",
      "Epoch [10/50] Loss: 24933.5942 | Fault Acc: 81.80% | Val Acc: 75.88%\n",
      "Epoch [11/50] Loss: 23903.4184 | Fault Acc: 83.50% | Val Acc: 78.24%\n",
      "Epoch [12/50] Loss: 21986.9120 | Fault Acc: 84.48% | Val Acc: 79.95%\n",
      "Epoch [13/50] Loss: 22229.0092 | Fault Acc: 85.48% | Val Acc: 78.47%\n",
      "Epoch [14/50] Loss: 21499.1406 | Fault Acc: 86.15% | Val Acc: 74.84%\n",
      "Epoch [15/50] Loss: 21856.2007 | Fault Acc: 87.18% | Val Acc: 76.42%\n",
      "Epoch [16/50] Loss: 20029.7237 | Fault Acc: 87.65% | Val Acc: 77.74%\n",
      "Epoch [17/50] Loss: 19102.9143 | Fault Acc: 88.42% | Val Acc: 80.61%\n",
      "Epoch [18/50] Loss: 18997.3904 | Fault Acc: 89.02% | Val Acc: 78.20%\n",
      "Epoch [19/50] Loss: 18430.2600 | Fault Acc: 89.55% | Val Acc: 79.14%\n",
      "Epoch [20/50] Loss: 18151.7207 | Fault Acc: 90.20% | Val Acc: 78.27%\n",
      "Epoch [21/50] Loss: 18411.8837 | Fault Acc: 90.65% | Val Acc: 79.27%\n",
      "Epoch [22/50] Loss: 17618.6412 | Fault Acc: 90.97% | Val Acc: 78.06%\n",
      "Epoch [23/50] Loss: 17643.3797 | Fault Acc: 91.65% | Val Acc: 80.37%\n",
      "Epoch [24/50] Loss: 17527.7287 | Fault Acc: 92.09% | Val Acc: 79.45%\n",
      "Epoch [25/50] Loss: 16563.4019 | Fault Acc: 92.31% | Val Acc: 80.45%\n",
      "Epoch [26/50] Loss: 16900.3948 | Fault Acc: 92.86% | Val Acc: 79.91%\n",
      "Epoch [27/50] Loss: 16351.2505 | Fault Acc: 93.24% | Val Acc: 78.64%\n",
      "Epoch [28/50] Loss: 16619.0082 | Fault Acc: 93.40% | Val Acc: 77.26%\n",
      "Epoch [29/50] Loss: 16751.3909 | Fault Acc: 93.64% | Val Acc: 79.14%\n",
      "Epoch [30/50] Loss: 15787.8798 | Fault Acc: 94.29% | Val Acc: 77.79%\n",
      "Epoch [31/50] Loss: 16076.3109 | Fault Acc: 94.42% | Val Acc: 77.29%\n",
      "Epoch [32/50] Loss: 16032.5251 | Fault Acc: 94.36% | Val Acc: 79.00%\n",
      "Epoch [33/50] Loss: 15723.0594 | Fault Acc: 94.88% | Val Acc: 79.47%\n",
      "Epoch [34/50] Loss: 15344.5508 | Fault Acc: 95.33% | Val Acc: 80.65%\n",
      "Epoch [35/50] Loss: 15163.8511 | Fault Acc: 94.92% | Val Acc: 79.31%\n",
      "Epoch [36/50] Loss: 15929.6178 | Fault Acc: 95.81% | Val Acc: 79.74%\n",
      "Epoch [37/50] Loss: 14678.2210 | Fault Acc: 95.56% | Val Acc: 78.54%\n",
      "Epoch [38/50] Loss: 15114.0559 | Fault Acc: 95.61% | Val Acc: 78.84%\n",
      "Epoch [39/50] Loss: 15425.7198 | Fault Acc: 95.88% | Val Acc: 76.80%\n",
      "Epoch [40/50] Loss: 15198.0073 | Fault Acc: 96.04% | Val Acc: 79.13%\n",
      "Epoch [41/50] Loss: 15038.3110 | Fault Acc: 95.96% | Val Acc: 78.61%\n",
      "Epoch [42/50] Loss: 14879.1036 | Fault Acc: 96.41% | Val Acc: 79.49%\n",
      "Epoch [43/50] Loss: 14688.6472 | Fault Acc: 96.59% | Val Acc: 78.74%\n",
      "Epoch [44/50] Loss: 14571.1632 | Fault Acc: 96.51% | Val Acc: 79.34%\n",
      "Epoch [45/50] Loss: 14089.4638 | Fault Acc: 96.66% | Val Acc: 79.66%\n",
      "Epoch [46/50] Loss: 13991.4870 | Fault Acc: 96.62% | Val Acc: 78.77%\n",
      "Epoch [47/50] Loss: 14379.8739 | Fault Acc: 97.16% | Val Acc: 78.96%\n",
      "Epoch [48/50] Loss: 14253.5503 | Fault Acc: 96.91% | Val Acc: 78.45%\n",
      "Epoch [49/50] Loss: 14232.8875 | Fault Acc: 96.82% | Val Acc: 79.20%\n",
      "Epoch [50/50] Loss: 14581.0803 | Fault Acc: 97.16% | Val Acc: 78.64%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. Cấu hình thiết bị và khởi tạo model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MDAMModel(num_fault_classes=4).to(device)\n",
    "\n",
    "# 2. Định nghĩa hàm Loss và Optimizer [cite: 305]\n",
    "mse_loss_fn = nn.MSELoss()           # Dùng cho cả tái tạo rung và tốc độ\n",
    "ce_loss_fn = nn.CrossEntropyLoss()    # Dùng cho phân loại lỗi\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. Vòng lặp huấn luyện (Training Loop)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_faults = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for vib_clean, speed_true, fault_true in train_loader:\n",
    "        # Chuyển dữ liệu lên GPU/CPU\n",
    "        vib_clean = vib_clean.to(device)   # [Batch, 1, 2048]\n",
    "        speed_true = speed_true.to(device) # [Batch, 1, 2048]\n",
    "        fault_true = fault_true.to(device) # [Batch]\n",
    "        \n",
    "        # Forward pass\n",
    "        vib_hat, fault_hat, speed_hat = model(vib_clean)\n",
    "        \n",
    "        # Tính toán các thành phần Loss [cite: 289, 436-438]\n",
    "        loss_vib = mse_loss_fn(vib_hat, vib_clean)      # Loss tái tạo rung\n",
    "        loss_speed = mse_loss_fn(speed_hat, speed_true) # Loss tái tạo tốc độ (MSE)\n",
    "        loss_fault = ce_loss_fn(fault_hat, fault_true)   # Loss phân loại lỗi\n",
    "        \n",
    "        # Tổng hợp Loss (Multi-task Learning) [cite: 168]\n",
    "        total_loss = loss_vib + loss_speed + loss_fault\n",
    "        \n",
    "        # Backward và cập nhật trọng số\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Thống kê\n",
    "        running_loss += total_loss.item()\n",
    "        _, predicted = torch.max(fault_hat, 1)\n",
    "        correct_faults += (predicted == fault_true).sum().item()\n",
    "        total_samples += fault_true.size(0)\n",
    "\n",
    "    # Đánh giá nhanh trên tập Validation\n",
    "    model.eval()\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for v_val, s_val, f_val in val_loader:\n",
    "            v_val, f_val = v_val.to(device), f_val.to(device)\n",
    "            _, f_hat, _ = model(v_val)\n",
    "            val_acc += (torch.max(f_hat, 1)[1] == f_val).sum().item()\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Loss: {running_loss/len(train_loader):.4f} | \"\n",
    "          f\"Fault Acc: {100*correct_faults/total_samples:.2f}% | \"\n",
    "          f\"Val Acc: {100*val_acc/len(val_loader.dataset):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2b81423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 70.34%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_acc = 0\n",
    "with torch.no_grad():\n",
    "    for v_test, s_test, f_test in test_loader:\n",
    "        v_test, f_test = v_test.to(device), f_test.to(device)\n",
    "        _, f_hat, _ = model(v_test)\n",
    "        test_acc += (torch.max(f_hat, 1)[1] == f_test).sum().item()\n",
    "            \n",
    "print(f\"Test Acc: {100*test_acc/len(test_loader.dataset):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
